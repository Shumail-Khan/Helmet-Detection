{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shumail-Khan/Helmet-Detection/blob/main/Helmet_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHIMOK3vLwmI"
      },
      "source": [
        "# Motorcycle Helmet Detection with YOLOv8\n",
        "\n",
        "**Setup required:**\n",
        "1. Go to the left sidebar ‚Üí üîë Secrets tab\n",
        "2. Add a new secret:\n",
        "   - Name: `ROBOFLOW_API_KEY`\n",
        "   - Value: your Roboflow API key (from https://app.roboflow.com/settings/api)\n",
        "   - Toggle \"Notebook access\" ON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "o61rYsMk5Qc0"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLzEYZ9BF7Dw"
      },
      "source": [
        "# Dataset Preparation with Roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97mFkwS7Ef_6"
      },
      "source": [
        "Steps:\n",
        "\n",
        "<ol>\n",
        "  <li>Go to Roboflow ‚Üí Sign up / log in (free).</li>\n",
        "  <li>Go to similar datasets ‚Üí Click Fork (or \"Use this Dataset\").</li>\n",
        "  <li>Add own images:</li>\n",
        "  <ul>\n",
        "    <li>Search Google/Images for \"motorcycle rider helmet\" and \"motorcycle rider no helmet\".</li>\n",
        "    <li>Upload them ‚Üí Use the Annotate tool to draw boxes and label.</li>\n",
        "  </ul>\n",
        "\n",
        "  <li>Generate a new Version:</li>\n",
        "    <ul>\n",
        "    <li>Preprocessing: Auto-Orient + Resize (Stretch to 640√ó640)</li>\n",
        "    <li>Augmentations: Flip, Rotation (¬±15¬∞), Blur</li>\n",
        "    </ul>\n",
        "\n",
        "  <li>Export the dataset:</li>\n",
        "  <ul>\n",
        "    <li>Format ‚Üí YOLOv8</li>\n",
        "    <li>Download the zip (or copy the code snippet)</li>\n",
        "    <li>Unzip it ‚Üí you will get a folder with data.yaml, train/, valid/, test/ folders.</li>\n",
        "  </ul>\n",
        "\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iV5hZVK2GQZ4"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "from google.colab import userdata\n",
        "rf = Roboflow(api_key=userdata.get('ROBOFLOW_API_KEY'))\n",
        "project = rf.workspace(\"shumail-39pbo\").project(\"bike-helmet-detection-2vdjo-byw6k\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9NHihm7GnQK"
      },
      "source": [
        "# Train YOLOv8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C88lt_cF5V2I",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained model (nano = fast & good enough for start)\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Train\n",
        "results = model.train(\n",
        "    data=\"./Bike-Helmet-Detection-2/data.yaml\",\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=8\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBcv-fwCHJV5"
      },
      "source": [
        "<bold><em>After training, best model is saved at runs/detect/train/weights/best.pt</bold></em>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L5o28wdJtBY"
      },
      "source": [
        "# Fine-tuning & mAP Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIJg5fj4J489"
      },
      "source": [
        "<ul>\n",
        "  <li>Look at the training logs</li>\n",
        "  <li>Common improvements:</li>\n",
        "  <ul>\n",
        "    <li>Increase epochs to 100‚Äì150 if mAP@50 is still rising.</li>\n",
        "    <li>Try yolov8s.pt (small) instead of nano for better accuracy.</li>\n",
        "    <li>Add more augmentations in Roboflow (mosaic, hsv, etc.) and re-export, to create new versions of datasets.</li>\n",
        "  </ul>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB_We6hn6f9C"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
        "metrics = model.val()   # runs on validation set automatically\n",
        "print(metrics.box.map)  # mAP@50:95\n",
        "print(metrics.box.map50)  # mAP@50 (most common metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSlamGI6Kmb-"
      },
      "source": [
        "# Inference Script + Webcam Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvM7QXGmNc6E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Change this path if your best.pt is somewhere else\n",
        "model = YOLO(\"runs/detect/train/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XE227yKZNoAI",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "test_folder = \"Bike-Helmet-Detection-2/test/images\"   # ‚Üê your test images folder\n",
        "\n",
        "# Create a folder to save results\n",
        "os.makedirs(\"test_results\", exist_ok=True)\n",
        "\n",
        "for img_name in os.listdir(test_folder):\n",
        "    if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img_path = os.path.join(test_folder, img_name)\n",
        "\n",
        "        results = model(img_path, conf=0.5, iou=0.45)   # adjust conf/iou if needed\n",
        "\n",
        "        # Show in Colab\n",
        "        annotated = results[0].plot()\n",
        "        cv2_imshow(annotated)\n",
        "\n",
        "        # Save annotated image\n",
        "        save_path = f\"test_results/{img_name}\"\n",
        "        cv2.imwrite(save_path, annotated)\n",
        "        print(f\"‚úì Processed and saved: {img_name}\")\n",
        "\n",
        "print(\"All test images processed! Check the 'test_results' folder.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "NNYU_BjjOcij"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# 1. Upload your test video\n",
        "uploaded = files.upload()\n",
        "video_path = list(uploaded.keys())[0]   # e.g. \"test_video.mp4\"\n",
        "\n",
        "# 2. Output video path\n",
        "output_path = \"output_helmet_detection.mp4\"\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, 20.0,\n",
        "                      (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "frame_count = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model(frame, conf=0.5)\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "    # Show every 10th frame in Colab so you can see progress\n",
        "    if frame_count % 10 == 0:\n",
        "        cv2_imshow(annotated_frame)\n",
        "        print(f\"Processing frame {frame_count}\")\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "print(\"Video processing complete! Download below:\")\n",
        "files.download(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIXKp9jzKlB4",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Video or webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret: break\n",
        "    results = model(frame, conf=0.5)\n",
        "    annotated = results[0].plot()\n",
        "    cv2.imshow(\"Helmet Detection\", annotated)\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSr34kFys7a9"
      },
      "source": [
        "# Report Accuracy & False Positives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZfw-XHos9m6"
      },
      "source": [
        "Dataset size & splits\n",
        "<ul>\n",
        "  <li>Total Images: 4587</li>\n",
        "  <li>Train Set: 3876</li>\n",
        "  <li>Valid Set: 476</li>\n",
        "  <li>Test Set: 235</li>\n",
        "</ul>\n",
        "Final mAP@50, Precision, Recall\n",
        "  <ul>\n",
        "    <li>mAP@50:95 = 0.62</li>\n",
        "    <li>mAP@50 = 0.88</li>\n",
        "  </ul>\n",
        "Confusion matrix (from model.val())<br>\n",
        "<img src='.\\runs\\detect\\val\\confusion_matrix_normalized.png' alt=\"Not Available\">\n",
        "False positives discussion:\n",
        "<ul>\n",
        "  <li>FPs: dark helmets at night, hats mistaken for helmets, people with round heads.</li>\n",
        "  <li>How to reduce: higher conf threshold (0.6‚Äì0.7), more night-time images in dataset, or add a \"person\" class first then check helmet on head.</li>\n",
        "</ul>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyO4GM6c8OFRc5TglGO1Qogm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}